# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import sys
import locale
from scipy import stats
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šç·¨ç¢¼
if sys.stdout.encoding != 'utf-8':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# é é¢è¨­å®š
st.set_page_config(page_title="æ™ºèƒ½æ•¸æ“šåˆ†æå·¥å…·", layout="wide")
st.title("ğŸ” æ™ºèƒ½æ•¸æ“šåˆ†æå·¥å…·")
st.markdown("ä¸Šå‚³æ•¸æ“šæª”æ¡ˆï¼Œç²å¾—å°ˆæ¥­ç´šè‡ªå‹•åˆ†æå ±å‘Š - ç„¡éœ€ API Keyï¼")

# åˆ†æå‡½æ•¸
def generate_data_insights(df, column):
    """ç”Ÿæˆæ•¸æ“šæ´å¯Ÿå ±å‘Š"""
    insights = []
    data = df[column].dropna()
    
    if len(data) == 0:
        return ["æ‰€é¸æ¬„ä½ç„¡æœ‰æ•ˆæ•¸æ“š"]
    
    # åŸºæœ¬çµ±è¨ˆ
    mean_val = data.mean()
    median_val = data.median()
    std_val = data.std()
    min_val = data.min()
    max_val = data.max()
    
    # 1. é›†ä¸­è¶¨å‹¢åˆ†æ
    if abs(mean_val - median_val) / std_val < 0.5:
        insights.append("ğŸ“Š **é›†ä¸­è¶¨å‹¢**: æ•¸æ“šåˆ†å¸ƒç›¸å°å°ç¨±ï¼Œå¹³å‡å€¼èˆ‡ä¸­ä½æ•¸æ¥è¿‘")
    elif mean_val > median_val:
        insights.append("ğŸ“Š **é›†ä¸­è¶¨å‹¢**: æ•¸æ“šå‘ˆç¾å³ååˆ†å¸ƒï¼Œå­˜åœ¨è¼ƒå¤§çš„æ¥µå€¼æ‹‰é«˜å¹³å‡å€¼")
    else:
        insights.append("ğŸ“Š **é›†ä¸­è¶¨å‹¢**: æ•¸æ“šå‘ˆç¾å·¦ååˆ†å¸ƒï¼Œå­˜åœ¨è¼ƒå°çš„æ¥µå€¼æ‹‰ä½å¹³å‡å€¼")
    
    # 2. é›¢æ•£ç¨‹åº¦åˆ†æ
    cv = std_val / abs(mean_val) if mean_val != 0 else float('inf')
    if cv < 0.1:
        insights.append("ğŸ“ˆ **è®Šç•°æ€§**: æ•¸æ“šè®ŠåŒ–å¾ˆå°ï¼Œç›¸ç•¶ç©©å®š")
    elif cv < 0.3:
        insights.append("ğŸ“ˆ **è®Šç•°æ€§**: æ•¸æ“šè®ŠåŒ–é©ä¸­ï¼Œå…·æœ‰ä¸€å®šç©©å®šæ€§")
    else:
        insights.append("ğŸ“ˆ **è®Šç•°æ€§**: æ•¸æ“šè®ŠåŒ–è¼ƒå¤§ï¼Œæ³¢å‹•æ€§é«˜")
    
    # 3. ç•°å¸¸å€¼æª¢æ¸¬
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data < lower_bound) | (data > upper_bound)]
    
    if len(outliers) > 0:
        outlier_ratio = len(outliers) / len(data) * 100
        insights.append(f"âš ï¸ **ç•°å¸¸å€¼**: ç™¼ç¾ {len(outliers)} å€‹ç•°å¸¸å€¼ ({outlier_ratio:.1f}%)ï¼Œå»ºè­°é€²ä¸€æ­¥æª¢æŸ¥")
    else:
        insights.append("âœ… **ç•°å¸¸å€¼**: æœªç™¼ç¾æ˜é¡¯ç•°å¸¸å€¼ï¼Œæ•¸æ“šå“è³ªè‰¯å¥½")
    
    # 4. åˆ†å¸ƒç‰¹å¾µ
    skewness = stats.skew(data)
    kurtosis = stats.kurtosis(data)
    
    if abs(skewness) < 0.5:
        skew_desc = "è¿‘ä¼¼å°ç¨±"
    elif skewness > 0.5:
        skew_desc = "å³åï¼ˆæ­£åï¼‰"
    else:
        skew_desc = "å·¦åï¼ˆè² åï¼‰"
    
    insights.append(f"ğŸ“‹ **åˆ†å¸ƒå½¢ç‹€**: {skew_desc}ï¼Œå³°åº¦ = {kurtosis:.2f}")
    
    # 5. æ•¸æ“šç¯„åœåˆ†æ
    data_range = max_val - min_val
    range_ratio = data_range / mean_val if mean_val != 0 else float('inf')
    insights.append(f"ğŸ“ **æ•¸æ“šç¯„åœ**: {data_range:.2f}ï¼Œç´„ç‚ºå¹³å‡å€¼çš„ {range_ratio:.1f} å€")
    
    # 6. å¯¦å‹™å»ºè­°
    if cv > 0.5:
        insights.append("ğŸ’¡ **å»ºè­°**: æ•¸æ“šæ³¢å‹•è¼ƒå¤§ï¼Œå»ºè­°åˆ†çµ„åˆ†ææˆ–å°‹æ‰¾å½±éŸ¿å› ç´ ")
    elif len(outliers) > len(data) * 0.1:
        insights.append("ğŸ’¡ **å»ºè­°**: ç•°å¸¸å€¼è¼ƒå¤šï¼Œå»ºè­°æª¢æŸ¥æ•¸æ“šæ”¶é›†éç¨‹")
    else:
        insights.append("ğŸ’¡ **å»ºè­°**: æ•¸æ“šå“è³ªè‰¯å¥½ï¼Œé©åˆé€²ä¸€æ­¥çµ±è¨ˆåˆ†æ")
    
    return insights

def detect_patterns(df, column):
    """æª¢æ¸¬æ•¸æ“šæ¨¡å¼"""
    patterns = []
    data = df[column].dropna()
    
    # è¶¨å‹¢åˆ†æï¼ˆå¦‚æœæ•¸æ“šæœ‰æ™‚é–“é †åºï¼‰
    if len(data) > 10:
        # ç°¡å–®è¶¨å‹¢æª¢æ¸¬
        x = np.arange(len(data))
        slope, intercept, r_value, p_value, std_err = stats.linregress(x, data)
        
        if abs(r_value) > 0.3 and p_value < 0.05:
            if slope > 0:
                patterns.append(f"ğŸ“ˆ **è¶¨å‹¢**: æ•¸æ“šå‘ˆç¾ä¸Šå‡è¶¨å‹¢ (ç›¸é—œä¿‚æ•¸: {r_value:.3f})")
            else:
                patterns.append(f"ğŸ“‰ **è¶¨å‹¢**: æ•¸æ“šå‘ˆç¾ä¸‹é™è¶¨å‹¢ (ç›¸é—œä¿‚æ•¸: {r_value:.3f})")
        else:
            patterns.append("â¡ï¸ **è¶¨å‹¢**: ç„¡æ˜é¡¯ç·šæ€§è¶¨å‹¢")
    
    # é€±æœŸæ€§æª¢æ¸¬ï¼ˆç°¡å–®ç‰ˆæœ¬ï¼‰
    if len(data) > 20:
        # æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡çš„å³°å€¼æ¨¡å¼
        rolling_mean = pd.Series(data).rolling(window=5).mean()
        peaks_valleys = np.diff(np.sign(np.diff(rolling_mean)))
        peak_count = np.sum(peaks_valleys < 0)
        
        if peak_count > len(data) // 10:
            patterns.append("ğŸ”„ **é€±æœŸæ€§**: æ•¸æ“šå¯èƒ½å­˜åœ¨é€±æœŸæ€§æ³¢å‹•")
    
    return patterns

def advanced_statistics(df, column):
    """é€²éšçµ±è¨ˆåˆ†æ"""
    data = df[column].dropna()
    stats_info = {}
    
    # å¸¸ç”¨çµ±è¨ˆé‡
    stats_info['åŸºæœ¬çµ±è¨ˆ'] = {
        'è§€æ¸¬æ•¸': len(data),
        'å¹³å‡å€¼': f"{data.mean():.4f}",
        'ä¸­ä½æ•¸': f"{data.median():.4f}",
        'æ¨™æº–å·®': f"{data.std():.4f}",
        'è®Šç•°ä¿‚æ•¸': f"{data.std()/abs(data.mean()):.4f}" if data.mean() != 0 else "N/A",
        'æœ€å°å€¼': f"{data.min():.4f}",
        'æœ€å¤§å€¼': f"{data.max():.4f}",
        'ç¯„åœ': f"{data.max() - data.min():.4f}"
    }
    
    # åˆ†ä½æ•¸
    stats_info['åˆ†ä½æ•¸åˆ†æ'] = {
        'ç¬¬10ç™¾åˆ†ä½': f"{data.quantile(0.1):.4f}",
        'ç¬¬25ç™¾åˆ†ä½ (Q1)': f"{data.quantile(0.25):.4f}",
        'ç¬¬50ç™¾åˆ†ä½ (ä¸­ä½æ•¸)': f"{data.quantile(0.5):.4f}",
        'ç¬¬75ç™¾åˆ†ä½ (Q3)': f"{data.quantile(0.75):.4f}",
        'ç¬¬90ç™¾åˆ†ä½': f"{data.quantile(0.9):.4f}",
        'å››åˆ†ä½è· (IQR)': f"{data.quantile(0.75) - data.quantile(0.25):.4f}"
    }
    
    # åˆ†å¸ƒç‰¹å¾µ
    stats_info['åˆ†å¸ƒç‰¹å¾µ'] = {
        'ååº¦ (Skewness)': f"{stats.skew(data):.4f}",
        'å³°åº¦ (Kurtosis)': f"{stats.kurtosis(data):.4f}",
        'è®Šç•°æ•¸': f"{data.var():.4f}",
        'æ¨™æº–èª¤': f"{data.std()/np.sqrt(len(data)):.4f}"
    }
    
    # å¸¸æ…‹æ€§æª¢å®š
    try:
        shapiro_stat, shapiro_p = stats.shapiro(data.sample(min(5000, len(data))))
        stats_info['çµ±è¨ˆæª¢å®š'] = {
            'Shapiro-Wilk çµ±è¨ˆé‡': f"{shapiro_stat:.4f}",
            'Shapiro-Wilk på€¼': f"{shapiro_p:.4f}",
            'å¸¸æ…‹æ€§': "å¯èƒ½ç¬¦åˆå¸¸æ…‹åˆ†å¸ƒ" if shapiro_p > 0.05 else "ä¸ç¬¦åˆå¸¸æ…‹åˆ†å¸ƒ"
        }
    except:
        stats_info['çµ±è¨ˆæª¢å®š'] = {'è¨»è¨˜': 'ç„¡æ³•åŸ·è¡Œå¸¸æ…‹æ€§æª¢å®š'}
    
    return stats_info

# æª”æ¡ˆä¸Šå‚³
uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ Excel æˆ– CSV æª”æ¡ˆ", type=["csv", "xlsx"])

if uploaded_file is not None:
    try:
        # è®€å–æª”æ¡ˆ
        if uploaded_file.name.endswith(".csv"):
            df = pd.read_csv(uploaded_file, encoding='utf-8')
        else:
            df = pd.read_excel(uploaded_file)
        
        st.success("âœ… æª”æ¡ˆè®€å–æˆåŠŸï¼")
        
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(uploaded_file, encoding='big5')
            st.success("âœ… æª”æ¡ˆè®€å–æˆåŠŸï¼")
        except:
            try:
                df = pd.read_csv(uploaded_file, encoding='gbk')
                st.success("âœ… æª”æ¡ˆè®€å–æˆåŠŸï¼")
            except Exception as e:
                st.error(f"âŒ æª”æ¡ˆè®€å–å¤±æ•—ï¼š{e}")
                st.stop()
    except Exception as e:
        st.error(f"âŒ æª”æ¡ˆè®€å–å¤±æ•—ï¼š{e}")
        st.stop()

    # è³‡æ–™é è¦½
    st.subheader("ğŸ“‹ è³‡æ–™é è¦½")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**è³‡æ–™ç­†æ•¸ï¼š** {len(df):,}")
        st.write(f"**æ¬„ä½æ•¸é‡ï¼š** {len(df.columns)}")
    
    with col2:
        missing_data = df.isnull().sum().sum()
        st.write(f"**ç¼ºå¤±å€¼ç¸½æ•¸ï¼š** {missing_data:,}")
        st.write(f"**è¨˜æ†¶é«”ä½¿ç”¨ï¼š** {df.memory_usage(deep=True).sum() / 1024:.1f} KB")
    
    # é¡¯ç¤ºå‰å¹¾è¡Œæ•¸æ“š
    st.dataframe(df.head(10), use_container_width=True)
    
    # è³‡æ–™å‹æ…‹æ‘˜è¦
    with st.expander("ğŸ“Š è³‡æ–™å‹æ…‹æ‘˜è¦"):
        dtype_summary = df.dtypes.value_counts()
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**æ¬„ä½å‹æ…‹çµ±è¨ˆï¼š**")
            for dtype, count in dtype_summary.items():
                st.write(f"â€¢ {dtype}: {count} å€‹æ¬„ä½")
        
        with col2:
            st.write("**ç¼ºå¤±å€¼çµ±è¨ˆï¼š**")
            missing_summary = df.isnull().sum()
            missing_cols = missing_summary[missing_summary > 0]
            if len(missing_cols) > 0:
                for col, missing_count in missing_cols.items():
                    percentage = (missing_count / len(df)) * 100
                    st.write(f"â€¢ {col}: {missing_count} ({percentage:.1f}%)")
            else:
                st.write("â€¢ ç„¡ç¼ºå¤±å€¼")

    # é¸æ“‡åˆ†ææ¬„ä½
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if not numeric_cols:
        st.warning("âš ï¸ æ‰¾ä¸åˆ°æ•¸å€¼æ¬„ä½ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦åŒ…å«æ•¸å€¼è³‡æ–™")
        st.stop()

    selected_col = st.selectbox("ğŸ¯ è«‹é¸æ“‡è¦åˆ†æçš„æ•¸å€¼æ¬„ä½", numeric_cols)

    # å»ºç«‹åˆ†é 
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“Š åŸºæœ¬çµ±è¨ˆ", "ğŸ“ˆ è¦–è¦ºåŒ–åˆ†æ", "ğŸ” æ·±åº¦æ´å¯Ÿ", "ğŸ“‹ é€²éšçµ±è¨ˆ", "ğŸ“ å®Œæ•´å ±å‘Š"])
    
    with tab1:
        st.subheader("ğŸ“Š åŸºæœ¬çµ±è¨ˆè³‡è¨Š")
        col1, col2 = st.columns(2)
        
        with col1:
            stats_summary = df[selected_col].describe()
            st.write("**æè¿°æ€§çµ±è¨ˆï¼š**")
            st.dataframe(stats_summary.to_frame().T, use_container_width=True)
        
        with col2:
            # é¡å¤–çµ±è¨ˆè³‡è¨Š
            data = df[selected_col].dropna()
            st.write("**é¡å¤–è³‡è¨Šï¼š**")
            st.metric("æœ‰æ•ˆè§€æ¸¬æ•¸", f"{len(data):,}")
            st.metric("ç¼ºå¤±å€¼", f"{df[selected_col].isnull().sum():,}")
            st.metric("è®Šç•°ä¿‚æ•¸", f"{data.std()/abs(data.mean()):.4f}" if data.mean() != 0 else "N/A")
            st.metric("ååº¦", f"{stats.skew(data):.4f}")

    with tab2:
        st.subheader("ğŸ“ˆ è¦–è¦ºåŒ–åˆ†æ")
        
        # å‰µå»ºäº’å‹•å¼åœ–è¡¨
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('æ•¸æ“šè¶¨å‹¢', 'åˆ†å¸ƒç›´æ–¹åœ–', 'ç®±å‹åœ–', 'çµ±è¨ˆæ‘˜è¦'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"type": "table"}]]
        )
        
        # è¶¨å‹¢åœ–
        fig.add_trace(
            go.Scatter(y=df[selected_col], mode='lines+markers', name='æ•¸å€¼', line=dict(width=2)),
            row=1, col=1
        )
        
        # ç›´æ–¹åœ–
        fig.add_trace(
            go.Histogram(x=df[selected_col], nbinsx=30, name='åˆ†å¸ƒ', opacity=0.7),
            row=1, col=2
        )
        
        # ç®±å‹åœ–
        fig.add_trace(
            go.Box(y=df[selected_col], name='ç®±å‹åœ–', boxpoints='outliers'),
            row=2, col=1
        )
        
        # çµ±è¨ˆè¡¨æ ¼
        stats_data = df[selected_col].describe()
        fig.add_trace(
            go.Table(
                header=dict(values=['çµ±è¨ˆé‡', 'æ•¸å€¼']),
                cells=dict(values=[stats_data.index, [f"{val:.4f}" for val in stats_data.values]])
            ),
            row=2, col=2
        )
        
        fig.update_layout(height=800, showlegend=False, title_text=f"ğŸ“Š {selected_col} å®Œæ•´åˆ†æ")
        st.plotly_chart(fig, use_container_width=True)
        
        # é¡å¤–çš„ Seaborn åœ–è¡¨
        st.subheader("ğŸ“Š åˆ†å¸ƒåˆ†æ")
        col1, col2 = st.columns(2)
        
        with col1:
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.histplot(data=df, x=selected_col, kde=True, ax=ax)
            ax.set_title(f'{selected_col} åˆ†å¸ƒåœ– (å«æ ¸å¯†åº¦ä¼°è¨ˆ)')
            st.pyplot(fig)
        
        with col2:
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.boxplot(data=df, y=selected_col, ax=ax)
            ax.set_title(f'{selected_col} ç®±å‹åœ–')
            st.pyplot(fig)

    with tab3:
        st.subheader("ğŸ” æ™ºèƒ½æ•¸æ“šæ´å¯Ÿ")
        
        # ç”Ÿæˆæ´å¯Ÿ
        insights = generate_data_insights(df, selected_col)
        patterns = detect_patterns(df, selected_col)
        
        st.write("### ğŸ¤– è‡ªå‹•åˆ†æçµæœ")
        for insight in insights:
            st.markdown(insight)
        
        if patterns:
            st.write("### ğŸ”„ æ¨¡å¼è­˜åˆ¥")
            for pattern in patterns:
                st.markdown(pattern)
        
        # ç›¸é—œæ€§åˆ†æï¼ˆå¦‚æœæœ‰å…¶ä»–æ•¸å€¼æ¬„ä½ï¼‰
        if len(numeric_cols) > 1:
            st.write("### ğŸ”— ç›¸é—œæ€§åˆ†æ")
            other_cols = [col for col in numeric_cols if col != selected_col]
            
            if other_cols:
                correlation_data = []
                for col in other_cols:
                    corr = df[selected_col].corr(df[col])
                    if not np.isnan(corr):
                        correlation_data.append({'æ¬„ä½': col, 'ç›¸é—œä¿‚æ•¸': corr, 'ç›¸é—œå¼·åº¦': 
                                               'å¼·' if abs(corr) > 0.7 else 'ä¸­' if abs(corr) > 0.3 else 'å¼±'})
                
                if correlation_data:
                    corr_df = pd.DataFrame(correlation_data)
                    corr_df = corr_df.sort_values('ç›¸é—œä¿‚æ•¸', key=abs, ascending=False)
                    st.dataframe(corr_df, use_container_width=True)

    with tab4:
        st.subheader("ğŸ“‹ é€²éšçµ±è¨ˆåˆ†æ")
        
        advanced_stats = advanced_statistics(df, selected_col)
        
        for category, stats_dict in advanced_stats.items():
            st.write(f"### {category}")
            
            # å‰µå»ºå…©åˆ—é¡¯ç¤º
            cols = st.columns(2)
            items = list(stats_dict.items())
            
            for i, (key, value) in enumerate(items):
                with cols[i % 2]:
                    st.metric(key, value)
        
        # ä¿¡è³´å€é–“è¨ˆç®—
        st.write("### ğŸ“Š ä¿¡è³´å€é–“")
        data = df[selected_col].dropna()
        confidence_levels = [0.90, 0.95, 0.99]
        
        ci_data = []
        for conf in confidence_levels:
            alpha = 1 - conf
            mean_val = data.mean()
            std_err = data.std() / np.sqrt(len(data))
            margin_error = stats.t.ppf(1 - alpha/2, len(data)-1) * std_err
            
            ci_data.append({
                'ä¿¡è³´æ°´æº–': f"{conf*100:.0f}%",
                'ä¸‹ç•Œ': f"{mean_val - margin_error:.4f}",
                'ä¸Šç•Œ': f"{mean_val + margin_error:.4f}",
                'èª¤å·®ç¯„åœ': f"Â±{margin_error:.4f}"
            })
        
        ci_df = pd.DataFrame(ci_data)
        st.dataframe(ci_df, use_container_width=True)

    with tab5:
        st.subheader("ğŸ“ å®Œæ•´åˆ†æå ±å‘Š")
        
        # ç”Ÿæˆå®Œæ•´å ±å‘Š
        report = f"""
# ğŸ“Š æ•¸æ“šåˆ†æå ±å‘Š

## åŸºæœ¬è³‡è¨Š
- **åˆ†ææ¬„ä½**: {selected_col}
- **è³‡æ–™ç­†æ•¸**: {len(df):,}
- **æœ‰æ•ˆè§€æ¸¬**: {len(df[selected_col].dropna()):,}
- **ç¼ºå¤±å€¼**: {df[selected_col].isnull().sum():,}
- **åˆ†ææ™‚é–“**: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

## çµ±è¨ˆæ‘˜è¦
"""
        
        # æ·»åŠ çµ±è¨ˆè³‡è¨Š
        stats_summary = df[selected_col].describe()
        for stat, value in stats_summary.items():
            report += f"- **{stat}**: {value:.4f}\n"
        
        report += "\n## ğŸ“ˆ ä¸»è¦ç™¼ç¾\n"
        
        # æ·»åŠ æ´å¯Ÿ
        insights = generate_data_insights(df, selected_col)
        for i, insight in enumerate(insights, 1):
            report += f"{i}. {insight}\n"
        
        # æ·»åŠ æ¨¡å¼åˆ†æ
        patterns = detect_patterns(df, selected_col)
        if patterns:
            report += "\n## ğŸ”„ ç™¼ç¾çš„æ¨¡å¼\n"
            for i, pattern in enumerate(patterns, 1):
                report += f"{i}. {pattern}\n"
        
        report += "\n## ğŸ’¡ å»ºè­°\n"
        report += "1. å®šæœŸç›£æ§æ•¸æ“šå“è³ªï¼Œç‰¹åˆ¥æ³¨æ„ç•°å¸¸å€¼\n"
        report += "2. å¯è€ƒæ…®é€²è¡Œæ›´æ·±å…¥çš„æ™‚é–“åºåˆ—åˆ†æ\n"
        report += "3. å»ºè­°èˆ‡å…¶ä»–ç›¸é—œè®Šæ•¸é€²è¡Œå¤šå…ƒåˆ†æ\n"
        report += "4. æ ¹æ“šæ¥­å‹™éœ€æ±‚è¨­å®šé©ç•¶çš„ç›£æ§é–¾å€¼\n"
        
        st.markdown(report)
        
        # æä¾›ä¸‹è¼‰æŒ‰éˆ•
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰åˆ†æå ±å‘Š",
            data=report,
            file_name=f"{selected_col}_analysis_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )

else:
    # ç¤ºä¾‹æ•¸æ“šå±•ç¤º
    st.info("ğŸ‘† è«‹ä¸Šå‚³æª”æ¡ˆé–‹å§‹åˆ†æï¼Œæˆ–æŸ¥çœ‹ä»¥ä¸‹åŠŸèƒ½èªªæ˜")
    
    with st.expander("ğŸ¯ åŠŸèƒ½ç‰¹è‰²"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ğŸ“Š çµ±è¨ˆåˆ†æ**")
            st.write("â€¢ å®Œæ•´æè¿°æ€§çµ±è¨ˆ")
            st.write("â€¢ åˆ†ä½æ•¸åˆ†æ")
            st.write("â€¢ åˆ†å¸ƒç‰¹å¾µæª¢æ¸¬")
            st.write("â€¢ ç•°å¸¸å€¼è­˜åˆ¥")
            
            st.write("**ğŸ” æ™ºèƒ½æ´å¯Ÿ**")
            st.write("â€¢ è‡ªå‹•æ¨¡å¼è­˜åˆ¥")
            st.write("â€¢ è¶¨å‹¢åˆ†æ")
            st.write("â€¢ æ•¸æ“šå“è³ªè©•ä¼°")
            st.write("â€¢ å¯¦ç”¨å»ºè­°ç”Ÿæˆ")
        
        with col2:
            st.write("**ğŸ“ˆ è¦–è¦ºåŒ–**")
            st.write("â€¢ äº’å‹•å¼åœ–è¡¨")
            st.write("â€¢ å¤šç¨®åœ–è¡¨é¡å‹")
            st.write("â€¢ åˆ†å¸ƒåˆ†æåœ–")
            st.write("â€¢ ç›¸é—œæ€§çŸ©é™£")
            
            st.write("**ğŸ“ å ±å‘ŠåŠŸèƒ½**")
            st.write("â€¢ å®Œæ•´åˆ†æå ±å‘Š")
            st.write("â€¢ Markdown æ ¼å¼åŒ¯å‡º")
            st.write("â€¢ å°ˆæ¥­çµ±è¨ˆè¡“èª")
            st.write("â€¢ å³æ™‚åˆ†æçµæœ")

# å´é‚Šæ¬„
with st.sidebar:
    st.markdown("### ğŸš€ æ™ºèƒ½åˆ†æå·¥å…·")
    st.markdown("**ç„¡éœ€ APIï¼Œæœ¬åœ°åˆ†æ**")
    
    st.markdown("### ğŸ“ æ”¯æ´æ ¼å¼")
    st.markdown("â€¢ CSV æª”æ¡ˆ (å¤šç¨®ç·¨ç¢¼)")
    st.markdown("â€¢ Excel æª”æ¡ˆ (.xlsx)")
    st.markdown("â€¢ è‡ªå‹•åµæ¸¬æ•¸å€¼æ¬„ä½")
    
    st.markdown("### â­ æ ¸å¿ƒåŠŸèƒ½")
    st.markdown("â€¢ ğŸ“Š å®Œæ•´çµ±è¨ˆåˆ†æ")
    st.markdown("â€¢ ğŸ¤– æ™ºèƒ½æ•¸æ“šæ´å¯Ÿ") 
    st.markdown("â€¢ ğŸ“ˆ äº’å‹•å¼è¦–è¦ºåŒ–")
    st.markdown("â€¢ ğŸ” ç•°å¸¸å€¼æª¢æ¸¬")
    st.markdown("â€¢ ğŸ“ å°ˆæ¥­å ±å‘Šç”Ÿæˆ")
    
    st.markdown("### ğŸ’¡ ä½¿ç”¨æŠ€å·§")
    st.markdown("â€¢ ä¸Šå‚³å‰æª¢æŸ¥æ•¸æ“šæ ¼å¼")
    st.markdown("â€¢ é¸æ“‡æœ‰æ„ç¾©çš„æ•¸å€¼æ¬„ä½")
    st.markdown("â€¢ æŸ¥çœ‹å„å€‹åˆ†é çš„ä¸åŒåˆ†æ")
    st.markdown("â€¢ ä¸‹è¼‰å ±å‘Šç•™å­˜çµæœ")
    
    st.markdown("---")
    st.markdown("**ğŸ”§ æŠ€è¡“æ¶æ§‹**")
    st.markdown("â€¢ Streamlit + Pandas")
    st.markdown("â€¢ Plotly + Seaborn")
    st.markdown("â€¢ SciPy çµ±è¨ˆåˆ†æ")
    st.markdown("â€¢ 100% æœ¬åœ°é‹ç®—")
